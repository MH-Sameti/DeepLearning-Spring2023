{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnKVArh_0qhm"
      },
      "source": [
        "# BYOL\n",
        "\n",
        "In this notebook we are going to implement [BYOL: Bootstrap Your Own Latent](https://arxiv.org/pdf/2006.07733.pdf) and compare the results of a classification task before and after pretraining the model with BYOL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E6nh_5Q2uIp"
      },
      "source": [
        "### Data Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B7vzr4sTnriT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import Callable, Tuple\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, Tensor\n",
        "from torchvision import transforms as T\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class RandomApply(nn.Module):\n",
        "    def __init__(self, fn: Callable, p: float):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # your code\n",
        "\n",
        "        if random.random() > self.p:\n",
        "          return x\n",
        "        else:\n",
        "          return self.fn(x)\n",
        "\n",
        "\n",
        "\n",
        "def default_augmentation(image_size: Tuple[int, int] = (224, 224)) -> nn.Module:\n",
        "    \"\"\"\n",
        "        1. resize images to 'image_size'\n",
        "        2. RandomApply color jitter\n",
        "        3. RandomApply grayscale\n",
        "        4. RandomApply horizon flip\n",
        "        5. RandomApply gaussian blur with kernel_size(3, 3), sigma=(1.5, 1.5)\n",
        "        6. RandomApply ResizedCrop to 'image_size'\n",
        "        7. Normalize\n",
        "        choosing hyperparameters that are not mentioned is up to you\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        # your code\n",
        "        T.Resize(size=image_size),\n",
        "        RandomApply(T.ColorJitter(0.8, 0.8, 0.8, 0.2), p=0.8),\n",
        "        T.RandomGrayscale(p=0.2),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        RandomApply(T.GaussianBlur((3, 3), (1.5, 1.5)), p=0.1),\n",
        "        T.RandomResizedCrop(size=image_size),\n",
        "        T.Normalize(\n",
        "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
        "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd29IvYa9vGD"
      },
      "source": [
        "# Model\n",
        "We will use ResNet18 as our representation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YoU-3B4FmtrZ"
      },
      "outputs": [],
      "source": [
        "def get_encoder_model():\n",
        "    resnet = torchvision.models.resnet18()\n",
        "    # remove last fully-connected layer\n",
        "    # your code\n",
        "    resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "    return resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtPDCprF9vGD"
      },
      "source": [
        "### Loss Function\n",
        "We need to use NormalizedMSELoss as our loss function.\n",
        "$$NormalizedMSELoss(v_1, v_2) = \\Vert \\bar{v_1} - \\bar{v_2}\\Vert_2^2 = 2 - 2.\\frac{\\langle v_1, v_2 \\rangle}{\\Vert v_1\\Vert_2 \\Vert v_2\\Vert_2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HlRer8D_9vGD"
      },
      "outputs": [],
      "source": [
        "class NormalizedMSELoss(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(NormalizedMSELoss,self).__init__()\n",
        "\n",
        "    def forward(self, view1: Tensor, view2: Tensor) -> Tensor:\n",
        "        # your code\n",
        "        v1 = F.normalize(view1, dim=-1)\n",
        "        v2 = F.normalize(view2, dim=-1)\n",
        "        return 2 - 2 * (v1 * v2).sum(dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6req5xT9vGE"
      },
      "source": [
        "### MLP\n",
        "Here you will implement a simple MLP class with one hidden layer with BatchNorm and ReLU activation, and a linear output layer. This class will be used for both the projections and the prediction networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5HIv4-i89vGE"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim: int=4096, projection_dim: int = 256, hidden_dim: int = 4096) -> None:\n",
        "        super(MLP,self).__init__()\n",
        "\n",
        "        # your code\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # your code\n",
        "        return self.net(x)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0XekqqI9vGE"
      },
      "source": [
        "### Encoder + Projector Network\n",
        "This is the network structure that is shared between online and target networks. It consists of our encoder model, followed by a projection MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nSMOFmm39vGE"
      },
      "outputs": [],
      "source": [
        "class EncoderProjecter(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 hidden_dim: int = 4096,\n",
        "                 projection_out_dim: int = 256\n",
        "                 ) -> None:\n",
        "        super(EncoderProjecter, self).__init__()\n",
        "\n",
        "        # your code\n",
        "        self.encoder = encoder\n",
        "        self.projector = MLP(512)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # your code\n",
        "        x = self.encoder(x).squeeze()\n",
        "        return self.projector(x)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOamqWLK9vGE"
      },
      "source": [
        "## BYOL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XTpgVsG19vGE"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model: nn.Module,\n",
        "                 hidden_dim: int = 4096,\n",
        "                 projection_out_dim: int = 256,\n",
        "                 target_decay: float = 0.99\n",
        "\n",
        "                ) -> None:\n",
        "        super(BYOL, self).__init__()\n",
        "        # your code\n",
        "        self.online_network = EncoderProjecter(model, hidden_dim, projection_out_dim)  # encoder + projector\n",
        "        self.online_predictor = MLP(256)\n",
        "        self.target_network = copy.deepcopy(self.online_network)\n",
        "        for p in self.target_network.parameters():\n",
        "          p.requires_grad = False\n",
        "        self.target_network.eval()\n",
        "        self.loss_function = NormalizedMSELoss()\n",
        "        self.target_decay = target_decay\n",
        "    @torch.no_grad()\n",
        "    def soft_update_target_network(self) -> None:\n",
        "        # your code\n",
        "         for online_params, target_params in zip(self.online_network.parameters(), self.target_network.parameters()):\n",
        "            target_params.data = (self.target_decay * target_params.data) + ((1 - self.target_decay) * online_params.data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, view1, view2) -> Tuple[Tensor]:\n",
        "        # return online projection and target projection of view\n",
        "        # your code\n",
        "        with torch.no_grad():\n",
        "          target_projection1 = self.target_network(view1)\n",
        "          target_projection2 = self.target_network(view2)\n",
        "\n",
        "        online_pred1 = self.online_predictor(self.online_network(view1))\n",
        "        online_pred2 = self.online_predictor(self.online_network(view2))\n",
        "\n",
        "        loss1 = self.loss_function(online_pred1, target_projection2)\n",
        "        loss2 = self.loss_function(online_pred2, target_projection1)\n",
        "\n",
        "        #self.soft_update_target_network()\n",
        "\n",
        "        return torch.mean(loss1 + loss2)\n",
        "    '''def loss(self, online_pred1, target_projection1, online_pred2, target_projection2):\n",
        "        # compute loss once for (online_prediction1, target_projection2) and once for (online_prediction2, target_projection1).\n",
        "        # then return the mean.\n",
        "        # your code\n",
        "\n",
        "\n",
        "\n",
        "        return (loss1 + loss2) / 2'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzcP89G4L2u"
      },
      "source": [
        "# STL10 Datasets\n",
        "\n",
        "We need 3 separate datasets from STL10 for this experiment:\n",
        "1. `\"train\"` -- Contains only labeled training images. Used for supervised training.\n",
        "2. `\"train+unlabeled\"` -- Contains training images, plus a large number of unlabelled images.  Used for self-supervised learning with BYOL.\n",
        "3. `\"test\"` -- Labeled test images.  We use it both as a validation set, and for computing the final model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lTVx52t9Kjf",
        "outputId": "93710355-530f-4bad-915b-264f45812dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [02:38<00:00, 16626326.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/stl10_binary.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import STL10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "TRAIN_DATASET = STL10(root=\"data\", split=\"train\", download=True, transform=ToTensor())\n",
        "TRAIN_UNLABELED_DATASET = STL10(root=\"data\", split=\"train+unlabeled\", download=True, transform=ToTensor())\n",
        "TEST_DATASET = STL10(root=\"data\", split=\"test\", download=True, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUHoXyEx9vGF"
      },
      "source": [
        "Create dataloaders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LJosngV99vGF"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "from torch.utils.data import DataLoader\n",
        "device = DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_loader = DataLoader(\n",
        "    TRAIN_DATASET,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    TEST_DATASET,\n",
        "    batch_size=256,\n",
        ")\n",
        "train_un_loader = DataLoader(\n",
        "    TRAIN_UNLABELED_DATASET,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdlrDnwR45bm"
      },
      "source": [
        "# Supervised Training without BYOL\n",
        "\n",
        "First create a classifier model by simply adding a linear layer on top of the encoder model. Then train the model using the labeled training set. Performance should be pretty good already."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.linear = nn.Linear(512, num_classes, device='cuda')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x).squeeze()\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "# Get the encoder model\n",
        "encoder = get_encoder_model().to(device)\n",
        "num_classes = 10\n",
        "classifier = Classifier(encoder, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 2e-4\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
        "num_epochs = 5\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    classifier.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(inputs.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = classifier(inputs.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "0aaYW9zi8YoP",
        "outputId": "79d98f3e-7821-43d5-c054-7af56d4099a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:15<01:01, 15.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Accuracy: 10.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:34, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Accuracy: 15.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:32<00:19,  9.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Accuracy: 40.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:41<00:09,  9.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Accuracy: 45.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:50<00:00, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Accuracy: 45.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "به علت کمبود وقت ۵ ایپاک آموزش داده شد. همچنین با ۱۵ ایپاک در حد ۴ درصد تفاوت دارد"
      ],
      "metadata": {
        "id": "2d_kgIyEJXlt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBTyX-f45Sgj"
      },
      "source": [
        "# Self-Supervised Training with BYOL\n",
        "\n",
        "Now perform the self-supervised training. This is the most computationally intensive part of the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZgSkamP9vGF",
        "outputId": "1130910a-2184-4094-ea44-9fb2663a5cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  5%|▌         | 1/20 [04:31<1:26:06, 271.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 13.009098197100684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [09:03<1:21:28, 271.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Loss: 0.11659725764911855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [13:33<1:16:49, 271.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Loss: 0.015903343723039143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [18:03<1:12:07, 270.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Loss: 0.00648481408279622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [22:32<1:07:31, 270.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Loss: 0.004222342373395804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [27:02<1:02:59, 269.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Loss: 0.0030689763834743644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [31:33<58:36, 270.46s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Loss: 0.0022416956726374337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [36:04<54:05, 270.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Loss: 0.00190783981270215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [40:34<49:35, 270.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Loss: 0.001542078610327735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [45:05<45:04, 270.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Loss: 0.0015028218740553712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [49:34<40:29, 269.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Loss: 0.00132805211478626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [54:04<35:59, 269.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Loss: 0.001988662034364097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [58:35<31:32, 270.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Loss: 0.002682100795027509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [1:03:04<27:00, 270.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Loss: 0.0019195920788206422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [1:07:33<22:28, 269.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Loss: 0.00380253968796751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [1:12:04<17:59, 269.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Loss: 0.002904784959355311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [1:16:34<13:30, 270.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Loss: 0.00850325170904398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [1:21:03<08:59, 269.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Loss: 0.001862303167627033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [1:25:35<04:30, 270.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Loss: 0.0006754969244866516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [1:30:05<00:00, 270.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Loss: 0.003070410899908893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "encoder2 = get_encoder_model()\n",
        "byol = BYOL(encoder2, 4096, 256, 0.99).to(device)\n",
        "Path = './content/'\n",
        "LR = 2e-4\n",
        "optimizer2 = optim.Adam(byol.parameters(), lr=LR)\n",
        "aug = default_augmentation((96,96))\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_un_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        with torch.no_grad():\n",
        "          v1 ,  v2 = aug(inputs), aug(inputs)\n",
        "\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        loss = byol(v1, v2)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer2.step()\n",
        "        byol.soft_update_target_network()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjMmW9Tj5k-j"
      },
      "source": [
        "# Supervised Training Again\n",
        "\n",
        "Extract the encoder network's state dictionary from BYOL, and load it into our ResNet18 model before starting training.  Then run supervised training, and watch the accuracy improve from last time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JT3ueQrcBeTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41334e85-2232-4b65-f2c4-a475a5f8543f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1/15 [00:09<02:07,  9.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Accuracy: 14.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:17<01:52,  8.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15, Accuracy: 36.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:26<01:45,  8.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15, Accuracy: 43.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:35<01:39,  9.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15, Accuracy: 45.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:44<01:30,  9.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15, Accuracy: 46.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:53<01:19,  8.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15, Accuracy: 51.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [01:02<01:10,  8.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15, Accuracy: 47.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:11<01:03,  9.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15, Accuracy: 51.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:20<00:53,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15, Accuracy: 53.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:29<00:44,  8.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15, Accuracy: 53.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:38<00:35,  8.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15, Accuracy: 54.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:47<00:26,  8.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15, Accuracy: 55.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:55<00:17,  8.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15, Accuracy: 55.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [02:04<00:08,  8.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15, Accuracy: 57.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:13<00:00,  8.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15, Accuracy: 57.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "encoder_ = torch.nn.Sequential(*list(byol.online_network.children())[:-1])\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "classifier2 = Classifier(encoder_, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 2e-4\n",
        "optimizer = optim.Adam(classifier2.parameters(), lr=LR)\n",
        "num_epochs = 15\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    classifier2.train()\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = classifier2(inputs.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    classifier2.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = classifier2(inputs.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Accuracy: {100 * correct / total:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
